{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-12T18:14:37.943237Z","iopub.execute_input":"2024-07-12T18:14:37.943560Z","iopub.status.idle":"2024-07-12T18:14:37.950327Z","shell.execute_reply.started":"2024-07-12T18:14:37.943528Z","shell.execute_reply":"2024-07-12T18:14:37.949401Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"! pip install pytorch-lightning --quiet\n! pip install lightning-bolts --quiet","metadata":{"execution":{"iopub.status.busy":"2024-07-12T18:14:37.953341Z","iopub.execute_input":"2024-07-12T18:14:37.953650Z","iopub.status.idle":"2024-07-12T18:15:02.929300Z","shell.execute_reply.started":"2024-07-12T18:14:37.953608Z","shell.execute_reply":"2024-07-12T18:15:02.928206Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom torchvision.datasets import CIFAR10\nfrom torch.utils.data import DataLoader\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelSummary\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom pl_bolts.models.autoencoders.components import(\nresnet18_decoder, resnet18_encoder)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T18:15:02.933768Z","iopub.execute_input":"2024-07-12T18:15:02.934118Z","iopub.status.idle":"2024-07-12T18:15:09.417905Z","shell.execute_reply.started":"2024-07-12T18:15:02.934081Z","shell.execute_reply":"2024-07-12T18:15:09.416913Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n  if not hasattr(numpy, tp_name):\n/opt/conda/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n  if not hasattr(numpy, tp_name):\n/opt/conda/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n/opt/conda/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n/opt/conda/lib/python3.10/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n  self.nce_loss = AmdimNCELoss(tclip)\n","output_type":"stream"}]},{"cell_type":"code","source":"Batch_size = 64\n\ntrain_dataset = CIFAR10(root='./data', train= True, transform= transforms.ToTensor(), download = True)\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=Batch_size, shuffle=True)\n\ntest_dataset = CIFAR10(root='./data', train= False, transform= transforms.ToTensor(), download = True)\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=Batch_size, shuffle=True)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse','ship','truck')","metadata":{"execution":{"iopub.status.busy":"2024-07-12T18:15:09.419183Z","iopub.execute_input":"2024-07-12T18:15:09.419472Z","iopub.status.idle":"2024-07-12T18:15:11.036665Z","shell.execute_reply.started":"2024-07-12T18:15:09.419446Z","shell.execute_reply":"2024-07-12T18:15:11.035901Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"next(iter(train_dataloader))[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-07-12T18:15:11.038181Z","iopub.execute_input":"2024-07-12T18:15:11.038460Z","iopub.status.idle":"2024-07-12T18:15:11.061788Z","shell.execute_reply.started":"2024-07-12T18:15:11.038430Z","shell.execute_reply":"2024-07-12T18:15:11.060950Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"torch.Size([64, 3, 32, 32])"},"metadata":{}}]},{"cell_type":"code","source":"next(iter(train_dataloader))[1].shape","metadata":{"execution":{"iopub.status.busy":"2024-07-12T18:15:11.062793Z","iopub.execute_input":"2024-07-12T18:15:11.063084Z","iopub.status.idle":"2024-07-12T18:15:11.083151Z","shell.execute_reply.started":"2024-07-12T18:15:11.063061Z","shell.execute_reply":"2024-07-12T18:15:11.082251Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"torch.Size([64])"},"metadata":{}}]},{"cell_type":"code","source":"y_val = next(iter(train_dataloader))[1]\ny = F.one_hot(y_val, num_classes = 10)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T18:15:11.084285Z","iopub.execute_input":"2024-07-12T18:15:11.084549Z","iopub.status.idle":"2024-07-12T18:15:11.107536Z","shell.execute_reply.started":"2024-07-12T18:15:11.084525Z","shell.execute_reply":"2024-07-12T18:15:11.106710Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"y[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-12T18:15:11.108654Z","iopub.execute_input":"2024-07-12T18:15:11.108930Z","iopub.status.idle":"2024-07-12T18:15:11.116277Z","shell.execute_reply.started":"2024-07-12T18:15:11.108906Z","shell.execute_reply":"2024-07-12T18:15:11.115311Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAE(pl.LightningModule):\n    \"\"\"\n    Lightning Module for VAE\n    \"\"\"\n    def __init__(self, enc_out_dim=256, latent_dim=512, input_height=32):\n        \"\"\"\n        Constructor\n        \"\"\"\n        # Initialize the lightning module\n        super().__init__()\n\n        # Save the input params\n        self.save_hyperparameters()\n\n        # Encoder Layers\n        self.encoder_conv_layers = nn.Sequential(\n            self.conv_layer(in_channels=4, out_channels=64),   # Input Channels = 4  [3 for RGB and 1 for label data]\n            self.conv_layer(in_channels=64, out_channels=128),\n            self.conv_layer(in_channels=128, out_channels=256)\n        )\n\n        # distribution parameters\n        self.fc_mu = nn.Linear(enc_out_dim * 26 * 26, latent_dim)    # 26 since input image size is reduced to 26 after 3 conv layers\n        self.fc_var = nn.Linear(enc_out_dim * 26 * 26, latent_dim)\n\n        # Decoder's Linear Layer\n        self.linear = nn.Linear(latent_dim + 10, enc_out_dim * 26 * 26)  # 10 [One for each class]\n\n        # Decoder Layers\n        self.decoder_conv_layers = nn.Sequential(\n            self.transpose_layer(in_channels=256, out_channels=128),\n            self.transpose_layer(in_channels=128, out_channels=64),\n            self.transpose_layer(in_channels=64, out_channels=3),\n        )\n\n        # for the gaussian likelihood\n        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n\n    def conv_layer(self, in_channels, out_channels):\n        \"\"\"\n        Function to return conv layer\n        \"\"\"\n        return nn.Sequential(\n            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, bias=False),\n            nn.ReLU()\n        )\n\n    def transpose_layer(self, in_channels, out_channels):\n        \"\"\"\n        Function to return Transpose layer\n        \"\"\"\n        return nn.Sequential(\n            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, bias=False),\n            nn.ReLU()\n        )\n\n    def encoder(self, x, y):\n        \"\"\"\n        Encoder Block of the VAE\n        \"\"\"\n        # Batch size and input dimensions\n        batch_size = x.shape[0]\n        img_height = x.shape[2]   # Height = Width\n\n        # Concatenate Label data to the image data\n        y = torch.argmax(y, dim=1).reshape((y.shape[0], 1, 1, 1))\n        y = torch.ones((batch_size, 1, img_height, img_height)).to(self.device) * y\n        concat_input = torch.cat((x, y), dim=1)\n\n        # Pass the concatenated input through the encoder layers and flatten it\n        x = self.encoder_conv_layers(concat_input)\n        x = x.view(batch_size, -1)\n        return x\n\n    def decoder(self, z, y):\n        \"\"\"\n        Decoder Block of VAE\n        \"\"\"\n        # Add 10 neurons (one for each class to the latent layer)\n        z = torch.cat((z, y.float()), dim=1)\n\n        # Latent layer\n        x_hat = F.relu(self.linear(z))\n        x_hat = x_hat.reshape(-1, 256, 26, 26)\n\n        # Decoder layers\n        x_hat = self.decoder_conv_layers(x_hat)\n        x_hat = torch.sigmoid(x_hat)\n        return x_hat\n\n    def configure_optimizers(self):\n        \"\"\"\n        Optimizer for model training\n        \"\"\"\n        return torch.optim.Adam(self.parameters(), lr=1e-4)\n\n    def gaussian_likelihood(self, mean, logscale, sample):\n        \"\"\"\n        \"\"\"\n        scale = torch.exp(logscale)\n        dist = torch.distributions.Normal(mean, scale)\n        log_pxz = dist.log_prob(sample)\n        return log_pxz.sum(dim=(1, 2, 3))\n\n    def kl_divergence(self, z, mu, std):\n        \"\"\"\n        \"\"\"\n        # --------------------------\n        # Monte carlo KL divergence\n        # --------------------------\n        # 1. define the first two probabilities (in this case Normal for both)\n        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n        q = torch.distributions.Normal(mu, std)\n\n        # 2. get the probabilities from the equation\n        log_qzx = q.log_prob(z)\n        log_pz = p.log_prob(z)\n\n        # kl\n        kl = (log_qzx - log_pz)\n        kl = kl.sum(-1)\n        return kl\n\n    def training_step(self, batch, batch_idx):\n        \"\"\"\n        Function to train the model\n        \"\"\"\n        # Input data\n        x, y = batch\n\n        # One-Hot encoding of label data\n        y = F.one_hot(y, num_classes=10)\n\n        # encode x to get the mu and variance parameters\n        x_encoded = self.encoder(x, y)\n\n        # Encoder output mu and sigma\n        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n\n        # sample z from q\n        std = torch.exp(log_var / 2)\n        q = torch.distributions.Normal(mu, std)\n        z = q.rsample()\n\n        # decoded\n        x_hat = self.decoder(z, y)\n\n        # reconstruction loss\n        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n\n        # kl\n        kl = self.kl_divergence(z, mu, std)\n\n        # elbo\n        elbo = (kl - recon_loss)\n        elbo = elbo.mean()\n\n        self.log_dict({\n            'elbo': elbo,\n            'kl': kl.mean(),\n            'recon_loss': recon_loss.mean(),\n            'reconstruction': recon_loss.mean(),\n            'kl': kl.mean(),\n        })\n\n        return elbo","metadata":{"execution":{"iopub.status.busy":"2024-07-12T18:15:11.117925Z","iopub.execute_input":"2024-07-12T18:15:11.118261Z","iopub.status.idle":"2024-07-12T18:15:11.148872Z","shell.execute_reply.started":"2024-07-12T18:15:11.118230Z","shell.execute_reply":"2024-07-12T18:15:11.147886Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Seed for deterministic results\npl.seed_everything(8)\n\n# Instance of the model\nmodel = VAE()\n\n# Trainer configuration\ntrainer = pl.Trainer(\n    callbacks=[ModelSummary(max_depth=1)],\n    gpus=1,\n    num_sanity_val_steps=1,\n    max_epochs=10\n    )\n\n# Train the model\ntrainer.fit(model, train_dataloader, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T18:23:38.738947Z","iopub.execute_input":"2024-07-12T18:23:38.739825Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n  rank_zero_deprecation(\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:106: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f182b1ce6b04cdab1f84af63ba64286"}},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'vae_cifar_model.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow, figure\nimport numpy as np\n\n\ndef vae_results(x, y, model, classes, correct_labels=True, num_outputs=25):\n    \"\"\"\n    Function to display output images generated by the model\n    \"\"\"\n    # Figure to display the results\n    figure(figsize=(8, 3), dpi=300)\n    device = model.device\n\n    # Set the model to eval mode\n    with torch.no_grad():\n        # Change the value to get incorrect label values\n        y_incorrect = y - 1                   # Reduce class value by 1\n        y_incorrect[y_incorrect == -1] = 9    # Change -1 to 9\n\n        # One-Hot Encoding\n        one_hot_y = F.one_hot(y, num_classes=10)\n        one_hot_incorrect_y = F.one_hot(y_incorrect, num_classes=10)\n\n        # Send correct labels to Encoder based on function argument\n        if correct_labels:\n            x_encoded = model.encoder(x.to(device), one_hot_y.to(device))\n        else:\n            x_encoded = model.encoder(x.to(device), one_hot_incorrect_y.to(device))\n\n        # Get mean and variance from encoder output\n        mu, log_var = model.fc_mu(x_encoded), model.fc_var(x_encoded)\n\n        # Calculate standard deviation\n        std = torch.exp(log_var/2)\n        q = torch.distributions.Normal(mu,std)\n        z = q.rsample()\n\n        # Send correct labels to Decoder based on function argument\n        if correct_labels:\n            x_hat = model.decoder(z, one_hot_y.to(device))\n        else:\n            x_hat = model.decoder(z, one_hot_incorrect_y.to(device))\n\n        # Plot Results\n        fig = plt.figure(figsize=(10,10))\n        for index in np.arange(num_outputs):\n            axs = fig.add_subplot(5, 5, index + 1, xticks=[], yticks=[])\n            img = x_hat[index].to('cpu')\n            plt.imshow(img.permute(1, 2, 0))\n\n            if correct_labels:\n                axs.set_title(f\"Label: {classes[y[index]]}\")\n            else:\n                axs.set_title(f\"Incorrect Label: {classes[y_incorrect[index]]}\\n Correct Label: {classes[y[index]]}\")\n\n        fig.tight_layout()\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y = next(iter(test_dataloader))\nvae_results(x, y, model, classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae_results(x, y, model, classes, correct_labels=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae_results(x, y, model, classes, correct_labels=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}